# Example 10: è‡ªä¸»å­¦ä¹  Agent - ç«æŠ€æ¸¸æˆ AI

## å¤æ‚åº¦
â­â­â­â­â­â­ ä¸“å®¶çº§ï¼ˆæœ€é«˜éš¾åº¦ï¼‰

## éœ€æ±‚

### èƒŒæ™¯
å®ç°ä¸€ä¸ªèƒ½å¤ŸæŒç»­å­¦ä¹ å’Œè‡ªæˆ‘è¿›åŒ–çš„æ¸¸æˆ AI Agentï¼Œé€šè¿‡æ„ŸçŸ¥-å†³ç­–-æ‰§è¡Œ-åé¦ˆçš„å¾ªç¯ï¼Œä¸æ–­ç§¯ç´¯ç»éªŒã€ä¼˜åŒ–ç­–ç•¥ï¼Œæœ€ç»ˆè¾¾åˆ°è¶…è¶Šè§„åˆ™å’Œåˆå§‹è®¾è®¡çš„è‡ªä¸»æ™ºèƒ½æ°´å¹³ã€‚è¿™æ˜¯ LangGraph èƒ½åŠ›çš„ç»ˆæå±•ç¤ºã€‚

### åŠŸèƒ½éœ€æ±‚

#### 1. æ¸¸æˆåœºæ™¯å®šä¹‰

**é€‰æ‹©æ¸¸æˆï¼šç®€åŒ–ç‰ˆå¾·å·æ‰‘å…‹ï¼ˆTexas Hold'emï¼‰**

åŸå› ï¼š
- æœ‰æ˜ç¡®çš„è§„åˆ™å’Œèƒœè´Ÿåˆ¤å®š
- éœ€è¦ç­–ç•¥æ€è€ƒï¼ˆæ¦‚ç‡è®¡ç®—ã€å¯¹æ‰‹å»ºæ¨¡ï¼‰
- åŒ…å«ä¸ç¡®å®šæ€§ï¼ˆç‰Œçš„éšæœºæ€§ï¼‰
- æœ‰å­¦ä¹ ä»·å€¼ï¼ˆä»å¤±è´¥ä¸­ä¼˜åŒ–ç­–ç•¥ï¼‰

æ¸¸æˆè§„åˆ™ï¼š
- 2åç©å®¶
- æ¯äººå‘2å¼ åº•ç‰Œ
- 5å¼ å…¬å…±ç‰Œåˆ†ä¸‰è½®å‘å‡ºï¼ˆç¿»ç‰Œ3å¼ ã€è½¬ç‰Œ1å¼ ã€æ²³ç‰Œ1å¼ ï¼‰
- æ¯è½®å¯ä»¥ï¼šè·Ÿæ³¨ã€åŠ æ³¨ã€å¼ƒç‰Œ
- æœ€åæ¯”ç‰Œé¢å¤§å°

#### 2. Agent æ ¸å¿ƒå¾ªç¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         æŒç»­å­¦ä¹ å¾ªç¯ï¼ˆæ— é™ï¼‰              â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. æ„ŸçŸ¥æ¸¸æˆçŠ¶æ€                    â”‚ â”‚
â”‚  â”‚     - æ‰‹ç‰Œ                         â”‚ â”‚
â”‚  â”‚     - å…¬å…±ç‰Œ                       â”‚ â”‚
â”‚  â”‚     - å¯¹æ‰‹è¡Œä¸º                     â”‚ â”‚
â”‚  â”‚     - ç­¹ç æƒ…å†µ                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                            â”‚
â”‚             â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  2. åˆ¶å®šç­–ç•¥                        â”‚ â”‚
â”‚  â”‚     - è®¡ç®—èƒœç‡                     â”‚ â”‚
â”‚  â”‚     - è¯„ä¼°é£é™©                     â”‚ â”‚
â”‚  â”‚     - å¯¹æ‰‹å»ºæ¨¡                     â”‚ â”‚
â”‚  â”‚     - æŸ¥è¯¢å†å²ç»éªŒ                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                            â”‚
â”‚             â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  3. æ‰§è¡ŒåŠ¨ä½œ                        â”‚ â”‚
â”‚  â”‚     - é€‰æ‹©è¡ŒåŠ¨                     â”‚ â”‚
â”‚  â”‚     - è®¡ç®—ç­¹ç                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                            â”‚
â”‚             â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  4. è§‚å¯Ÿç»“æœ                        â”‚ â”‚
â”‚  â”‚     - å¯¹æ‰‹ååº”                     â”‚ â”‚
â”‚  â”‚     - è¿™è½®è¾“èµ¢                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                            â”‚
â”‚             â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  5. å­˜å‚¨è®°å¿†                        â”‚ â”‚
â”‚  â”‚     - çŸ­æœŸè®°å¿†ï¼šæœ¬å±€æ¸¸æˆ            â”‚ â”‚
â”‚  â”‚     - é•¿æœŸè®°å¿†ï¼šæ‰€æœ‰æ¸¸æˆç»éªŒ        â”‚ â”‚
â”‚  â”‚     - å¯¹æ‰‹ç‰¹å¾åº“                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                            â”‚
â”‚             â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  6. ç­–ç•¥ä¼˜åŒ–                        â”‚ â”‚
â”‚  â”‚     - åˆ†æå¤±è´¥åŸå›                  â”‚ â”‚
â”‚  â”‚     - æ›´æ–°ç­–ç•¥æƒé‡                 â”‚ â”‚
â”‚  â”‚     - å‘ç°æ–°æ¨¡å¼                   â”‚ â”‚
â”‚  â”‚     - æ·˜æ±°ä½æ•ˆç­–ç•¥                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                            â”‚
â”‚             â””â”€â”€â”€â”€â”€â–º è¿›å…¥ä¸‹ä¸€è½®æ¸¸æˆ       â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3. è¯¦ç»†æ¨¡å—è®¾è®¡

**æ¨¡å—1ï¼šæ„ŸçŸ¥ç³»ç»Ÿï¼ˆPerceptionï¼‰**

èŒè´£ï¼šå…¨é¢æ„ŸçŸ¥å½“å‰æ¸¸æˆçŠ¶æ€

è¾“å…¥ï¼šæ¸¸æˆç¯å¢ƒ
è¾“å‡ºï¼šç»“æ„åŒ–çš„çŠ¶æ€è¡¨ç¤º

```python
class GameState:
    # è‡ªå·±çš„ä¿¡æ¯
    my_hand: List[Card]  # æ‰‹ç‰Œ
    my_chips: int        # ç­¹ç 
    my_position: str     # ä½ç½®ï¼ˆåº„å®¶/éåº„å®¶ï¼‰
    
    # å…¬å…±ä¿¡æ¯
    community_cards: List[Card]  # å…¬å…±ç‰Œ
    pot_size: int                # åº•æ± 
    current_bet: int             # å½“å‰æ³¨é¢
    round_name: str              # è½®æ¬¡ï¼ˆpreflop/flop/turn/riverï¼‰
    
    # å¯¹æ‰‹ä¿¡æ¯
    opponent_chips: int
    opponent_last_action: str  # fold/call/raise
    opponent_bet_amount: int
    
    # å†å²ä¿¡æ¯
    betting_history: List[Action]
```

æ„ŸçŸ¥èŠ‚ç‚¹å®ç°ï¼š
```python
def perceive(state):
    """æ„ŸçŸ¥æ¸¸æˆçŠ¶æ€"""
    # è§£æç‰Œé¢
    hand_strength = calculate_hand_strength(state)
    
    # è®¡ç®—èƒœç‡
    win_probability = monte_carlo_simulation(
        my_hand=state["my_hand"],
        community=state["community_cards"],
        num_simulations=1000
    )
    
    # å¯¹æ‰‹å»ºæ¨¡
    opponent_profile = load_opponent_model(state["opponent_id"])
    
    return {
        "hand_strength": hand_strength,
        "win_probability": win_probability,
        "opponent_profile": opponent_profile,
        "perceived_state": state
    }
```

---

**æ¨¡å—2ï¼šç­–ç•¥åˆ¶å®šï¼ˆStrategy Planningï¼‰**

èŒè´£ï¼šåŸºäºå½“å‰çŠ¶æ€å’Œå†å²ç»éªŒåˆ¶å®šå†³ç­–

ç­–ç•¥ç±»å‹ï¼š
1. **åŸºç¡€ç­–ç•¥ï¼ˆRule-basedï¼‰**
   - ç‰ŒåŠ›é˜ˆå€¼ç­–ç•¥
   - ä½ç½®ç­–ç•¥
   - åº•æ± èµ”ç‡è®¡ç®—

2. **ç»éªŒç­–ç•¥ï¼ˆExperience-basedï¼‰**
   - æŸ¥è¯¢ç›¸ä¼¼å†å²å±€é¢
   - ä½¿ç”¨å‘é‡æ•°æ®åº“æ£€ç´¢
   - å‚è€ƒè¿‡å»çš„æˆåŠŸ/å¤±è´¥æ¡ˆä¾‹

3. **å¯¹æ‰‹é€‚åº”ç­–ç•¥ï¼ˆOpponent Modelingï¼‰**
   - æ¿€è¿›å‹å¯¹æ‰‹ â†’ æ›´ä¿å®ˆ
   - ä¿å®ˆå‹å¯¹æ‰‹ â†’ æ›´æ¿€è¿›
   - è¯ˆå”¬é¢‘ç‡åˆ†æ

4. **åŠ¨æ€ç­–ç•¥ï¼ˆDynamicï¼‰**
   - æ ¹æ®ç­¹ç é‡è°ƒæ•´
   - æ ¹æ®æ¸¸æˆé˜¶æ®µè°ƒæ•´
   - æ ¹æ®å­¦ä¹ åˆ°çš„æ¨¡å¼è°ƒæ•´

ç­–ç•¥è¯„åˆ†ï¼š
```python
def plan_strategy(state):
    """åˆ¶å®šç­–ç•¥"""
    # 1. åŸºç¡€è¯„åˆ†
    base_score = evaluate_hand_strength(state)
    
    # 2. ç»éªŒåŠ æˆ
    similar_cases = query_memory(
        hand=state["my_hand"],
        community=state["community_cards"],
        opponent_action=state["opponent_last_action"],
        top_k=5
    )
    experience_adjustment = analyze_similar_cases(similar_cases)
    
    # 3. å¯¹æ‰‹å»ºæ¨¡
    opponent_model = state["opponent_profile"]
    opponent_adjustment = calculate_opponent_factor(opponent_model)
    
    # 4. ç»¼åˆå†³ç­–
    strategies = [
        {"action": "fold", "score": ...},
        {"action": "call", "score": ...},
        {"action": "raise_small", "score": ...},
        {"action": "raise_large", "score": ...},
        {"action": "all_in", "score": ...},
    ]
    
    # æ·»åŠ æ¢ç´¢å› å­ï¼ˆé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼‰
    if random.random() < state["exploration_rate"]:
        return random.choice(strategies)
    
    return max(strategies, key=lambda x: x["score"])
```

---

**æ¨¡å—3ï¼šåŠ¨ä½œæ‰§è¡Œï¼ˆAction Executionï¼‰**

èŒè´£ï¼šå°†ç­–ç•¥è½¬åŒ–ä¸ºå…·ä½“è¡ŒåŠ¨

```python
def execute_action(state):
    """æ‰§è¡ŒåŠ¨ä½œ"""
    action = state["planned_action"]
    
    # æ‰§è¡Œå¹¶è·å–ç»“æœ
    result = game_engine.take_action(
        player_id=state["my_id"],
        action=action["action"],
        amount=action.get("amount", 0)
    )
    
    return {
        "action_taken": action,
        "game_state_after": result["new_state"],
        "opponent_response": result["opponent_action"]
    }
```

---

**æ¨¡å—4ï¼šç»“æœè§‚å¯Ÿï¼ˆObservationï¼‰**

èŒè´£ï¼šè§‚å¯Ÿè¡ŒåŠ¨çš„å³æ—¶å’Œé•¿æœŸç»“æœ

```python
def observe_result(state):
    """è§‚å¯Ÿç»“æœ"""
    observations = {
        "immediate": {
            "opponent_response": state["opponent_response"],
            "pot_change": calculate_pot_change(state),
            "position_change": evaluate_position(state),
        },
        "round_end": None,  # å¦‚æœè¿™è½®ç»“æŸ
        "game_end": None,   # å¦‚æœæ•´å±€ç»“æŸ
    }
    
    # å¦‚æœæ•´å±€ç»“æŸ
    if state["game_ended"]:
        observations["game_end"] = {
            "result": "win" if state["i_won"] else "lose",
            "final_pot": state["final_pot"],
            "showdown": state["cards_revealed"],
        }
    
    return observations
```

---

**æ¨¡å—5ï¼šè®°å¿†å­˜å‚¨ï¼ˆMemory Storageï¼‰**

èŒè´£ï¼šå¤šå±‚æ¬¡è®°å¿†ç³»ç»Ÿ

**çŸ­æœŸè®°å¿†ï¼ˆWorking Memoryï¼‰**
- èŒƒå›´ï¼šå½“å‰è¿™ä¸€å±€æ¸¸æˆ
- å†…å®¹ï¼šæ‰€æœ‰è½®æ¬¡çš„å†³ç­–å’Œç»“æœ
- ç”¨é€”ï¼šæœ¬å±€å†…çš„å¯¹æ‰‹å»ºæ¨¡

**é•¿æœŸè®°å¿†ï¼ˆLong-term Memoryï¼‰**
- èŒƒå›´ï¼šæ‰€æœ‰å†å²æ¸¸æˆ
- å­˜å‚¨æ–¹å¼ï¼šå‘é‡æ•°æ®åº“ï¼ˆå¦‚ Chromaã€Pineconeï¼‰
- æ£€ç´¢æ–¹å¼ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢

**å¯¹æ‰‹ç‰¹å¾åº“ï¼ˆOpponent Profilesï¼‰**
- æ¯ä¸ªå¯¹æ‰‹çš„è¡Œä¸ºç‰¹å¾
- ç»Ÿè®¡æ•°æ®ï¼š
  - è¯ˆå”¬é¢‘ç‡
  - æ¿€è¿›åº¦
  - å¼ƒç‰Œé˜ˆå€¼
  - å¸¸ç”¨æ¨¡å¼

**ç­–ç•¥çŸ¥è¯†åº“ï¼ˆStrategy Libraryï¼‰**
- æˆåŠŸç­–ç•¥é›†åˆ
- æ¯ä¸ªç­–ç•¥çš„æˆåŠŸç‡
- é€‚ç”¨åœºæ™¯æ ‡è®°

å®ç°ï¼š
```python
def store_memory(state):
    """å­˜å‚¨è®°å¿†"""
    # 1. çŸ­æœŸè®°å¿†ï¼ˆæœ¬å±€ï¼‰
    state["working_memory"].append({
        "round": state["round_number"],
        "action": state["action_taken"],
        "result": state["observations"],
        "timestamp": time.time()
    })
    
    # 2. é•¿æœŸè®°å¿†ï¼ˆå¦‚æœæ¸¸æˆç»“æŸï¼‰
    if state["game_ended"]:
        game_summary = create_game_summary(state)
        
        # å‘é‡åŒ–å¹¶å­˜å‚¨
        embedding = create_embedding(game_summary)
        vector_db.add(
            embedding=embedding,
            metadata=game_summary,
            id=f"game_{state['game_id']}"
        )
        
        # 3. æ›´æ–°å¯¹æ‰‹æ¡£æ¡ˆ
        update_opponent_profile(
            opponent_id=state["opponent_id"],
            game_data=game_summary
        )
        
        # 4. æ›´æ–°ç­–ç•¥è¯„åˆ†
        update_strategy_scores(
            strategies_used=state["strategies_used"],
            game_result=state["result"]
        )
    
    return state
```

---

**æ¨¡å—6ï¼šç­–ç•¥ä¼˜åŒ–ï¼ˆStrategy Optimizationï¼‰**

èŒè´£ï¼šä»ç»éªŒä¸­å­¦ä¹ ï¼Œä¼˜åŒ–å†³ç­–æ¨¡å‹

å­¦ä¹ æœºåˆ¶ï¼š

**A. ç»éªŒå›æ”¾ï¼ˆExperience Replayï¼‰**
```python
def experience_replay(state):
    """ä»å†å²ç»éªŒä¸­å­¦ä¹ """
    # éšæœºé‡‡æ ·å†å²æ¸¸æˆ
    past_games = sample_from_memory(n=50)
    
    for game in past_games:
        # é‡æ–°è¯„ä¼°è¿‡å»çš„å†³ç­–
        for decision in game["decisions"]:
            # ç”¨å½“å‰çŸ¥è¯†é‡æ–°è¯„åˆ†
            current_score = evaluate_with_current_model(decision)
            past_score = decision["original_score"]
            
            # å¦‚æœè¯„åˆ†æå‡ï¼Œè¯´æ˜å­¦åˆ°äº†æ–°ä¸œè¥¿
            if abs(current_score - past_score) > threshold:
                # æ›´æ–°æ¨¡å‹
                update_model(decision, current_score)
```

**B. æ¨¡å¼å‘ç°ï¼ˆPattern Discoveryï¼‰**
```python
def discover_patterns(state):
    """å‘ç°æ–°æ¨¡å¼"""
    # èšç±»åˆ†æå†å²å†³ç­–
    decision_clusters = cluster_decisions(
        all_decisions=load_all_decisions(),
        method="k-means",
        n_clusters=10
    )
    
    # åˆ†ææ¯ä¸ªèšç±»çš„ç‰¹å¾
    for cluster in decision_clusters:
        pattern = {
            "typical_situation": extract_features(cluster),
            "best_action": find_most_successful_action(cluster),
            "success_rate": calculate_success_rate(cluster),
        }
        
        # å¦‚æœå‘ç°é«˜æˆåŠŸç‡çš„æ–°æ¨¡å¼
        if pattern["success_rate"] > 0.7:
            add_to_strategy_library(pattern)
```

**C. ç­–ç•¥æ·˜æ±°ï¼ˆStrategy Pruningï¼‰**
```python
def prune_strategies(state):
    """æ·˜æ±°ä½æ•ˆç­–ç•¥"""
    for strategy in state["strategy_library"]:
        # è®¡ç®—æœ€è¿‘è¡¨ç°
        recent_performance = evaluate_recent_performance(
            strategy=strategy,
            last_n_games=100
        )
        
        # å¦‚æœæŒç»­è¡¨ç°ä¸ä½³ï¼Œé™ä½æƒé‡æˆ–åˆ é™¤
        if recent_performance < threshold:
            strategy["weight"] *= 0.8  # é™æƒ
            
        if strategy["weight"] < 0.1:
            remove_strategy(strategy)  # æ·˜æ±°
```

**D. å‚æ•°è°ƒä¼˜ï¼ˆHyperparameter Tuningï¼‰**
```python
def optimize_parameters(state):
    """ä¼˜åŒ–å…³é”®å‚æ•°"""
    parameters = {
        "exploration_rate": state["exploration_rate"],
        "risk_tolerance": state["risk_tolerance"],
        "bluff_frequency": state["bluff_frequency"],
        # ... æ›´å¤šå‚æ•°
    }
    
    # åŸºäºæœ€è¿‘è¡¨ç°è°ƒæ•´
    recent_win_rate = calculate_recent_win_rate(last_n=100)
    
    if recent_win_rate < 0.4:
        # è¡¨ç°ä¸ä½³ï¼Œå¢åŠ æ¢ç´¢
        parameters["exploration_rate"] *= 1.2
    elif recent_win_rate > 0.6:
        # è¡¨ç°å¾ˆå¥½ï¼Œå‡å°‘æ¢ç´¢ï¼Œå¼ºåŒ–åˆ©ç”¨
        parameters["exploration_rate"] *= 0.9
    
    return parameters
```

#### 4. çŠ¶æ€ç®¡ç†

```python
class AgentState(TypedDict):
    # æ¸¸æˆçŠ¶æ€
    game_state: GameState
    game_id: str
    game_number: int  # ç¬¬å‡ å±€æ¸¸æˆ
    
    # æ„ŸçŸ¥
    perceived_state: dict
    hand_strength: float
    win_probability: float
    
    # ç­–ç•¥
    available_strategies: list
    planned_action: dict
    
    # æ‰§è¡Œ
    action_taken: dict
    opponent_response: dict
    
    # è§‚å¯Ÿ
    observations: dict
    
    # è®°å¿†
    working_memory: list  # çŸ­æœŸ
    long_term_memory_ref: str  # é•¿æœŸè®°å¿†å¼•ç”¨
    
    # å­¦ä¹ 
    strategies_used: list
    strategy_scores: dict
    exploration_rate: float
    
    # å¯¹æ‰‹å»ºæ¨¡
    opponent_id: str
    opponent_profile: dict
    
    # æ€§èƒ½æŒ‡æ ‡
    total_games_played: int
    win_rate: float
    avg_profit: float
    learning_progress: dict
```

#### 5. å®Œæ•´æµç¨‹å›¾

```python
from langgraph.graph import StateGraph, END

workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("perceive", perceive_node)
workflow.add_node("plan_strategy", strategy_node)
workflow.add_node("execute_action", execute_node)
workflow.add_node("observe_result", observe_node)
workflow.add_node("store_memory", memory_node)
workflow.add_node("optimize_strategy", optimize_node)

# æ·»åŠ è¾¹
workflow.set_entry_point("perceive")
workflow.add_edge("perceive", "plan_strategy")
workflow.add_edge("plan_strategy", "execute_action")
workflow.add_edge("execute_action", "observe_result")
workflow.add_edge("observe_result", "store_memory")

# æ¡ä»¶è¾¹ï¼šå†³å®šæ˜¯å¦ç»§ç»­æ¸¸æˆ
workflow.add_conditional_edges(
    "store_memory",
    decide_next,
    {
        "continue_game": "perceive",      # ç»§ç»­æœ¬å±€
        "optimize": "optimize_strategy",  # æœ¬å±€ç»“æŸï¼Œä¼˜åŒ–
        "end": END                        # å…¨éƒ¨ç»“æŸ
    }
)

workflow.add_conditional_edges(
    "optimize_strategy",
    decide_after_optimize,
    {
        "play_again": "perceive",  # å¼€å§‹æ–°ä¸€å±€
        "end": END                 # ç»“æŸ
    }
)

app = workflow.compile()
```

### æŠ€æœ¯è¦æ±‚

#### LangGraph å­¦ä¹ ç‚¹
- æŒæ¡æ— é™å¾ªç¯çš„ Agent è®¾è®¡
- ç†è§£é•¿æœŸè®°å¿†çš„é›†æˆï¼ˆå‘é‡æ•°æ®åº“ï¼‰
- å­¦ä¹ ç­–ç•¥çš„åŠ¨æ€æ›´æ–°
- æŒæ¡å¹¶è¡Œæ‰§è¡Œï¼ˆå¤šä¸ªæ¸¸æˆåŒæ—¶è¿›è¡Œï¼‰
- ç†è§£å¼ºåŒ–å­¦ä¹ ä¸ LangGraph çš„ç»“åˆ
- å­¦ä¹ è‡ªé€‚åº”å‚æ•°è°ƒæ•´

#### å®ç°è¦ç‚¹

1. **å‘é‡æ•°æ®åº“é›†æˆ**ï¼š
```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

memory_db = Chroma(
    collection_name="poker_experiences",
    embedding_function=OpenAIEmbeddings()
)

def query_similar_situations(current_state):
    query_text = f"Hand: {current_state['hand']}, Community: {current_state['community']}"
    results = memory_db.similarity_search(query_text, k=5)
    return results
```

2. **ç­–ç•¥æƒé‡æ›´æ–°**ï¼š
```python
def update_strategy_weights(strategy_id, result):
    """æ ¹æ®ç»“æœæ›´æ–°ç­–ç•¥æƒé‡"""
    strategy = load_strategy(strategy_id)
    
    # ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡
    alpha = 0.1
    if result == "win":
        strategy["weight"] = (1 - alpha) * strategy["weight"] + alpha * 1.0
    else:
        strategy["weight"] = (1 - alpha) * strategy["weight"] + alpha * 0.0
    
    save_strategy(strategy)
```

3. **å¹¶è¡Œæ¸¸æˆ**ï¼š
```python
# åŒæ—¶è¿è¡Œå¤šä¸ªæ¸¸æˆåŠ é€Ÿå­¦ä¹ 
async def parallel_training(n_games=100):
    tasks = []
    for i in range(n_games):
        task = app.ainvoke({"game_id": f"game_{i}"})
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return results
```

### éªŒæ”¶æ ‡å‡†

1. **å­¦ä¹ èƒ½åŠ›**
   - èƒœç‡éšæ¸¸æˆå±€æ•°æå‡
   - èƒ½å‘ç°å¹¶åˆ©ç”¨å¯¹æ‰‹å¼±ç‚¹
   - ç­–ç•¥åº“ä¸æ–­ä¸°å¯Œ

2. **é€‚åº”èƒ½åŠ›**
   - èƒ½å¤Ÿé€‚åº”ä¸åŒé£æ ¼çš„å¯¹æ‰‹
   - åœ¨ä¸åŒç­¹ç é‡ä¸‹è°ƒæ•´ç­–ç•¥
   - æ ¹æ®å±€åŠ¿å˜åŒ–åŠ¨æ€è°ƒæ•´

3. **è®°å¿†ç³»ç»Ÿ**
   - èƒ½å¤Ÿæ£€ç´¢ç›¸ä¼¼å†å²å±€é¢
   - è®°å¿†ä¸ä¼šæ— é™å¢é•¿ï¼ˆæœ‰æ·˜æ±°æœºåˆ¶ï¼‰
   - æ£€ç´¢é€Ÿåº¦å¿«ï¼ˆ<100msï¼‰

4. **æ€§èƒ½æå‡**
   - å‰100å±€ vs å100å±€èƒœç‡å¯¹æ¯”
   - å¯¹æŠ—è§„åˆ™å‹ AI çš„èƒœç‡
   - å¹³å‡æ¯å±€æ”¶ç›Šæå‡

### ç¤ºä¾‹è¾“å…¥è¾“å‡º

**è®­ç»ƒè¿‡ç¨‹æ¼”ç¤º**

```
==========================================
åˆå§‹åŒ– Agent
==========================================
[ç³»ç»Ÿåˆå§‹åŒ–]
âœ“ åˆ›å»ºå‘é‡æ•°æ®åº“
âœ“ åˆå§‹åŒ–ç­–ç•¥åº“ï¼ˆ10ä¸ªåŸºç¡€ç­–ç•¥ï¼‰
âœ“ è®¾ç½®æ¢ç´¢ç‡ï¼š0.3
âœ“ åŠ è½½å¯¹æ‰‹æ•°æ®åº“

å‡†å¤‡å¼€å§‹è®­ç»ƒ...

==========================================
ç¬¬ 1 å±€æ¸¸æˆ
==========================================
å¯¹æ‰‹: RandomBotï¼ˆéšæœºAIï¼‰
åˆå§‹ç­¹ç : 1000

--- ç¬¬1è½®: Pre-flop ---
[æ„ŸçŸ¥]
æˆ‘çš„æ‰‹ç‰Œ: â™ A â™¥K (å¼ºç‰Œ)
ä½ç½®: åº„å®¶
å¯¹æ‰‹è¡Œä¸º: Call

[ç­–ç•¥åˆ¶å®š]
æŸ¥è¯¢å†å²ç»éªŒ: æ²¡æœ‰ç›¸å…³ç»éªŒï¼ˆç¬¬ä¸€å±€ï¼‰
åŸºç¡€è¯„åˆ†: 8.5/10
å†³ç­–: Raise 50

[æ‰§è¡Œ]
âœ“ åŠ æ³¨ 50
åº•æ± : 110

[è§‚å¯Ÿ]
å¯¹æ‰‹ååº”: Callï¼ˆè·Ÿæ³¨ï¼‰
â†’ æ¨æµ‹: å¯¹æ‰‹å¯èƒ½æœ‰ä¸­ç­‰ç‰ŒåŠ›

--- ç¬¬2è½®: Flop ---
å…¬å…±ç‰Œ: â™ K â™¦7 â™£2 (æˆ‘æœ‰ä¸€å¯¹K)

[æ„ŸçŸ¥]
ç‰ŒåŠ›: é¡¶å¯¹é¡¶è¸¢è„š
èƒœç‡ä¼°ç®—: 82% (è’™ç‰¹å¡æ´›1000æ¬¡æ¨¡æ‹Ÿ)

[ç­–ç•¥]
å†³ç­–: Raise 100

[æ‰§è¡Œ]
âœ“ åŠ æ³¨ 100

[è§‚å¯Ÿ]
å¯¹æ‰‹: Foldï¼ˆå¼ƒç‰Œï¼‰
â†’ æˆ‘èµ¢å¾—åº•æ±  110

--- æ¸¸æˆç»“æŸ ---
ç»“æœ: âœ… èƒœåˆ©
æ”¶ç›Š: +60 ç­¹ç 
æœ€ç»ˆç­¹ç : 1060

[å­˜å‚¨è®°å¿†]
âœ“ è®°å½•è¿™å±€æ¸¸æˆ
âœ“ æ›´æ–°å¯¹æ‰‹æ¡£æ¡ˆ: RandomBot - å®¹æ˜“å¼ƒç‰Œ
âœ“ ç­–ç•¥"å¼ºç‰Œæ¿€è¿›"è¡¨ç°è‰¯å¥½ â†’ æƒé‡ +0.1

==========================================
ç¬¬ 50 å±€æ¸¸æˆï¼ˆå­¦ä¹ ä¸­ï¼‰
==========================================
å¯¹æ‰‹: AggressiveBotï¼ˆæ¿€è¿›AIï¼‰
å½“å‰ç­¹ç : 1420

--- Pre-flop ---
æˆ‘çš„æ‰‹ç‰Œ: â™¥9 â™¦8 (ä¸­ç­‰ç‰Œ)

[æ„ŸçŸ¥]
å¯¹æ‰‹: AggressiveBot
å¯¹æ‰‹ç‰¹å¾ï¼ˆä»è®°å¿†åŠ è½½ï¼‰:
  - è¯ˆå”¬é¢‘ç‡: 45% (éå¸¸é«˜)
  - æ¿€è¿›åº¦: 85%
  - å¼ƒç‰Œç‡: 15% (å¾ˆå°‘å¼ƒç‰Œ)

[ç­–ç•¥]
æŸ¥è¯¢å†å²: æ‰¾åˆ°3æ¬¡ç±»ä¼¼æƒ…å†µ
  - æ¡ˆä¾‹1: å¯¹æŠ—æ¿€è¿›å¯¹æ‰‹ï¼Œä¿å®ˆè·Ÿæ³¨ï¼Œåæ¥èµ¢äº†
  - æ¡ˆä¾‹2: è¯ˆå”¬å¤±è´¥ï¼ŒæŸå¤±200
  - æ¡ˆä¾‹3: å¼ƒç‰Œé¿å…å¤§æŸå¤±

ç»¼åˆå†³ç­–: Callï¼ˆè·Ÿæ³¨ï¼Œçœ‹å…¬å…±ç‰Œï¼‰
åŸå› : å¯¹æ‰‹ç»å¸¸è¯ˆå”¬ï¼Œå€¼å¾—çœ‹çœ‹

[æ‰§è¡Œ]
âœ“ è·Ÿæ³¨

--- Flop ---
å…¬å…±ç‰Œ: â™¥10 â™¦J â™ Q (æˆ‘æœ‰é¡ºå­!)

[æ„ŸçŸ¥]
ç‰ŒåŠ›: é¡ºå­
èƒœç‡: 95%

[ç­–ç•¥]
å¯¹æŠ—æ¿€è¿›å¯¹æ‰‹ç­–ç•¥: è¯±æ•Œæ·±å…¥
å†³ç­–: Checkï¼ˆè¿‡ç‰Œï¼‰
é¢„æœŸ: å¯¹æ‰‹ä¼šå¤§æ³¨è¯ˆå”¬

[æ‰§è¡Œ]
âœ“ è¿‡ç‰Œ

[è§‚å¯Ÿ]
å¯¹æ‰‹: All-in 500ï¼ï¼ˆæœç„¶è¯ˆå”¬ï¼‰

[ç­–ç•¥é‡æ–°è¯„ä¼°]
æˆ‘æœ‰åšæœç‰Œï¼ˆæœ€å¼ºï¼‰ï¼Œç«‹å³è·Ÿæ³¨
å†³ç­–: Call All-in

[æ‰§è¡Œ]
âœ“ è·Ÿæ³¨

--- Showdown ---
å¯¹æ‰‹ç‰Œ: â™£7 â™ 3 (ä»€ä¹ˆéƒ½æ²¡æœ‰ï¼Œçº¯è¯ˆå”¬)
ç»“æœ: âœ… æˆ‘èµ¢ï¼
æ”¶ç›Š: +500
æœ€ç»ˆç­¹ç : 1920

[è®°å¿†æ›´æ–°]
âœ“ å¼ºåŒ–ç­–ç•¥: "å¯¹æŠ—æ¿€è¿›å¯¹æ‰‹æ—¶ï¼Œæœ‰å¥½ç‰Œå¯è¯±æ•Œ"
âœ“ ç­–ç•¥æƒé‡å¤§å¹…æå‡
âœ“ å¯¹æ‰‹å»ºæ¨¡å‡†ç¡®æ€§ +5%

==========================================
ç¬¬ 100 å±€æ¸¸æˆï¼ˆå·²æœ‰ç»éªŒï¼‰
==========================================
å½“å‰ç­¹ç : 2150
ç´¯è®¡èƒœç‡: 58%

[ç­–ç•¥åº“çŠ¶æ€]
- æ€»ç­–ç•¥æ•°: 23ä¸ªï¼ˆæ–°å­¦ä¹ äº†13ä¸ªï¼‰
- é¡¶çº§ç­–ç•¥:
  1. "å¼ºç‰Œæ¿€è¿›" (æƒé‡: 0.92)
  2. "å¯¹æŠ—æ¿€è¿›å¯¹æ‰‹è¯±æ•Œ" (æƒé‡: 0.88)
  3. "ä½ç½®ä¼˜åŠ¿åˆ©ç”¨" (æƒé‡: 0.85)
- æ·˜æ±°ç­–ç•¥: 5ä¸ªä½æ•ˆç­–ç•¥å·²ç§»é™¤

[å¯¹æ‰‹æ•°æ®åº“]
- RandomBot: 85%èƒœç‡
- AggressiveBot: 62%èƒœç‡
- ConservativeBot: 71%èƒœç‡
- SmartBot: 45%èƒœç‡ï¼ˆéœ€è¦æ›´å¤šå­¦ä¹ ï¼‰

--- æ¸¸æˆè¿›è¡Œ ---
[ä½¿ç”¨ä¼˜åŒ–åçš„ç­–ç•¥ï¼Œè¡¨ç°å‡ºè‰²]

==========================================
ç¬¬ 500 å±€æ¸¸æˆï¼ˆé«˜çº§é˜¶æ®µï¼‰
==========================================
å½“å‰ç­¹ç : 4850
ç´¯è®¡èƒœç‡: 67%

[æ–°å‘ç°çš„æ¨¡å¼]
æ¨¡å¼#12: "ä¸‰æ¬¡å°æ³¨è¯±å¯¼è¯ˆå”¬"
  - é€‚ç”¨åœºæ™¯: æœ‰å¼ºç‰Œï¼Œå¯¹æ‰‹æ¿€è¿›
  - æˆåŠŸç‡: 78%
  - å‘ç°äº: ç¬¬287-350å±€ä¹‹é—´
  - çŠ¶æ€: å·²æ·»åŠ åˆ°ç­–ç•¥åº“

[è‡ªæˆ‘ä¼˜åŒ–]
æ¢ç´¢ç‡: 0.3 â†’ 0.12ï¼ˆå‡å°‘éšæœºæ€§ï¼Œæ›´å¤šåˆ©ç”¨å·²å­¦çŸ¥è¯†ï¼‰
é£é™©å®¹å¿åº¦: åŠ¨æ€è°ƒæ•´ï¼ˆæ ¹æ®ç­¹ç é‡ï¼‰

[å¯¹æ‰‹å»ºæ¨¡å‡çº§]
ç°åœ¨èƒ½è¯†åˆ«7ç§å¯¹æ‰‹ç±»å‹:
1. å®Œå…¨éšæœºå‹
2. æ¿€è¿›å‹
3. ä¿å®ˆå‹
4. ç´§å‡¶å‹
5. æ¾å¼±å‹
6. ä½ç½®å‹ï¼ˆæ ¹æ®ä½ç½®æ”¹å˜ç­–ç•¥ï¼‰
7. é€‚åº”å‹ï¼ˆä¹Ÿåœ¨å­¦ä¹ ï¼‰

[æ€§èƒ½å¯¹æ¯”]
å‰100å±€å¹³å‡æ”¶ç›Š: +1.5 ç­¹ç /å±€
ç¬¬400-500å±€å¹³å‡æ”¶ç›Š: +8.7 ç­¹ç /å±€
æå‡: 5.8å€ï¼

==========================================
ç¬¬ 1000 å±€ - é‡Œç¨‹ç¢‘
==========================================
æ€»æ¸¸æˆæ•°: 1000å±€
æ€»èƒœç‡: 71%
æœ€ç»ˆç­¹ç : 12,400 (12.4å€èµ·å§‹ç­¹ç )

[å­¦ä¹ æˆæœæ€»ç»“]

ç­–ç•¥è¿›åŒ–:
- åˆå§‹: 10ä¸ªè§„åˆ™ç­–ç•¥
- ç°åœ¨: 47ä¸ªç­–ç•¥ï¼ˆ37ä¸ªè‡ªä¸»å­¦ä¹ ï¼‰
- ç­–ç•¥æ ‘æ·±åº¦: 3å±‚

è®°å¿†ç³»ç»Ÿ:
- å­˜å‚¨æ¸¸æˆ: 1000å±€
- å­˜å‚¨å†³ç­–ç‚¹: 18,756ä¸ª
- å‘é‡æ£€ç´¢å¹³å‡è€—æ—¶: 45ms
- è®°å¿†å‘½ä¸­ç‡: 82%

å¯¹æ‰‹å»ºæ¨¡:
- å¯¹æŠ—è¿‡çš„å¯¹æ‰‹: 15ä¸ª
- è¯†åˆ«çš„è¡Œä¸ºæ¨¡å¼: 67ç§
- å¹³å‡å»ºæ¨¡å‡†ç¡®åº¦: 78%

åˆ›æ–°å‘ç°:
å‘ç°äº†3ä¸ªè¶…è¶Šåˆå§‹è§„åˆ™çš„ç­–ç•¥:
1. "åŠ¨æ€ç­¹ç æ¯”ä¾‹ä¸‹æ³¨"ï¼ˆä¼ ç»ŸAIå°‘ç”¨ï¼‰
2. "å¤šè½®å°æ³¨å¿ƒç†æˆ˜"ï¼ˆéœ€è¦å¯¹æ‰‹å»ºæ¨¡ï¼‰
3. "ä½ç½®-ç‰ŒåŠ›è”åˆè¯„ä¼°"ï¼ˆå¤æ‚å†³ç­–æ ‘ï¼‰

ä¸ä¼ ç»ŸAIå¯¹æ¯”:
- vs è§„åˆ™å‹AI: 83%èƒœç‡
- vs ä¼ ç»Ÿæœºå™¨å­¦ä¹ AI: 58%èƒœç‡
- vs äººç±»æ–°æ‰‹: ä¼°è®¡75%èƒœç‡

[èƒ½åŠ›è¯„ä¼°]
âœ… å·²æŒæ¡: åŸºæœ¬ç­–ç•¥ã€æ¦‚ç‡è®¡ç®—
âœ… å·²æŒæ¡: å¯¹æ‰‹å»ºæ¨¡ã€é€‚åº”æ€§è°ƒæ•´
âœ… å·²æŒæ¡: ç»éªŒå­¦ä¹ ã€æ¨¡å¼å‘ç°
ğŸ”„ å­¦ä¹ ä¸­: å¤æ‚å¿ƒç†åšå¼ˆ
ğŸ”„ å­¦ä¹ ä¸­: å¤šå¯¹æ‰‹åŒæ—¶å»ºæ¨¡

çŠ¶æ€: ğŸ“ å·²è¾¾åˆ°ä¸­çº§åä¸Šæ°´å¹³
å»ºè®®: ç»§ç»­è®­ç»ƒå¯¹æŠ—æ›´å¼ºAI
```

### æ‰©å±•æ€è€ƒ

å®ŒæˆåŸºç¡€éœ€æ±‚åï¼Œå¯ä»¥è€ƒè™‘ï¼š

1. **æ›´å¤æ‚çš„æ¸¸æˆ**
   - å¤šäººå¾·å·æ‰‘å…‹ï¼ˆ3-9äººï¼‰
   - å…¶ä»–æ¸¸æˆï¼ˆè±¡æ£‹ã€å›´æ£‹ï¼‰
   - å®æ—¶æˆ˜ç•¥æ¸¸æˆ

2. **é«˜çº§å­¦ä¹ ç®—æ³•**
   - é›†æˆå¼ºåŒ–å­¦ä¹ ï¼ˆDQNã€PPOï¼‰
   - è‡ªå¯¹å¼ˆè®­ç»ƒï¼ˆAlphaGo æ¨¡å¼ï¼‰
   - è¯¾ç¨‹å­¦ä¹ ï¼ˆä»ç®€å•å¯¹æ‰‹åˆ°å›°éš¾å¯¹æ‰‹ï¼‰

3. **å…ƒå­¦ä¹ èƒ½åŠ›**
   - å­¦ä¹ å¦‚ä½•å­¦ä¹ 
   - å¿«é€Ÿé€‚åº”æ–°å¯¹æ‰‹ï¼ˆFew-shotï¼‰
   - è¿ç§»å­¦ä¹ åˆ°æ–°æ¸¸æˆ

4. **å¤šAgentåä½œ**
   - å›¢é˜Ÿæ¸¸æˆï¼ˆå¦‚æ¡¥ç‰Œï¼‰
   - Agenté—´çŸ¥è¯†å…±äº«
   - é›†ä½“æ™ºèƒ½æ¶Œç°

5. **å¯è§£é‡Šæ€§**
   - å†³ç­–è¿‡ç¨‹å¯è§†åŒ–
   - ç­–ç•¥è§£é‡Šç”Ÿæˆ
   - å­¦ä¹ è·¯å¾„è¿½è¸ª

6. **æ€§èƒ½ä¼˜åŒ–**
   - å¹¶è¡Œæ¸¸æˆè®­ç»ƒ
   - åˆ†å¸ƒå¼è®°å¿†ç³»ç»Ÿ
   - GPUåŠ é€Ÿæ¨ç†

7. **å¯¹æŠ—è®­ç»ƒ**
   - å¯¹æŠ—æ€§å¯¹æ‰‹ç”Ÿæˆ
   - å‘ç°Agentå¼±ç‚¹
   - æŒç»­å®‰å…¨æ€§æµ‹è¯•

8. **äººæœºäº¤äº’**
   - å‘äººç±»ç©å®¶å­¦ä¹ 
   - è§£é‡Šç»™äººç±»å¬
   - æ•™å­¦æ¨¡å¼

### æ€»ç»“

è¿™æ˜¯ LangGraph çš„ç»ˆæåº”ç”¨åœºæ™¯ï¼Œå±•ç¤ºäº†ï¼š
- âœ… å¤æ‚å¾ªç¯å’ŒçŠ¶æ€ç®¡ç†
- âœ… é•¿æœŸè®°å¿†å’ŒçŸ¥è¯†ç§¯ç´¯
- âœ… è‡ªä¸»å­¦ä¹ å’Œç­–ç•¥ä¼˜åŒ–
- âœ… åŠ¨æ€é€‚åº”å’Œæ¨¡å¼å‘ç°
- âœ… å¤šå±‚å†³ç­–å’Œå…ƒè®¤çŸ¥

è¿™ä¸ªé¡¹ç›®ç»¼åˆè¿ç”¨äº†å‰é¢9ä¸ªç¤ºä¾‹çš„æ‰€æœ‰æŠ€æœ¯ï¼Œä»£è¡¨äº† LangGraph æ„å»ºè‡ªä¸»æ™ºèƒ½ç³»ç»Ÿçš„å®Œæ•´èƒ½åŠ›ã€‚
